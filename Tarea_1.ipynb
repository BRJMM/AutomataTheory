{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOisiZS523HL"
      },
      "source": [
        "# Tarea 1 (2024)\n",
        "Profesor: Tomás de Camino Beck, Ph.D.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd2t5Bj_2tGF"
      },
      "source": [
        "---\n",
        "\n",
        "### Instrucciones Generales\n",
        "\n",
        "- **Entrega**: *3 de Septiembre* antes de media noche. La tarea debe ser enviada por un miembro del equipo\n",
        "-**Lectura**:  Gran parte de los problemas se basan en el capítulo 4 del libro, apoyado en los capítulos anteriores. Puede que tenga que revisar secciones no vistas en clase.\n",
        "\n",
        "- **Formato de Entrega:** Los problemas deben ser entregados como un archivo Jupyter Notebook (.ipynb) de Google Colab que incluya todas las soluciones, explicaciones, ejemplos y pruebas solicitadas. Enviar al email del profesor.\n",
        "- **Estructura del Informe:**\n",
        "  - **Equipo:** Indicar nombre completo e identificación de cada miebro\n",
        "  - **Introducción:** Breve introducción a cada problema, explicando el enfoque general.\n",
        "  - **Código:** Cada problema debe incluir el código bien comentado.\n",
        "  - **Ejemplos:** Deben incluirse ejemplos de uso del código con entradas específicas y resultados esperados.\n",
        "  - **Pruebas:** Incluir casos de prueba que demuestren la funcionalidad del código, con explicaciones de los resultados.\n",
        "  - **Conclusión:** Breve conclusión sobre cada problema, discutiendo cualquier desafío encontrado y cómo fue resuelto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONDo2wLZuAS3"
      },
      "source": [
        "# Base Source Code and utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "import unittest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7SsjDj0uaR7"
      },
      "source": [
        "## DFA\n",
        "\n",
        "En caso de que necesitemos una clase DFA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "lJnrrmsuuF03"
      },
      "outputs": [],
      "source": [
        "class DFA:\n",
        "    def __init__(self, Q, Sigma, delta, q0, F):\n",
        "        self.Q = Q          # Conjunto de estados\n",
        "        self.Sigma = Sigma  # Alfabeto\n",
        "        self.delta = delta  # Función de transición\n",
        "        self.q0 = q0        # Estado inicial\n",
        "        self.F = F          # Conjunto de estados finales\n",
        "\n",
        "    def head(self, w):\n",
        "        \"\"\"Devuelve el primer símbolo de la palabra w.\"\"\"\n",
        "        return w[0] if w else None\n",
        "\n",
        "    def tail(self, w):\n",
        "        \"\"\"Devuelve la palabra w sin su primer símbolo.\"\"\"\n",
        "        return w[1:] if w else \"\"\n",
        "\n",
        "    def MemDFA(self, w, q):\n",
        "        if w == \"\":\n",
        "            return q in self.F\n",
        "        else:\n",
        "            a = self.head(w)        # Usando head(w)\n",
        "            w_tail = self.tail(w)   # Usando tail(w)\n",
        "            q_next = self.delta[q][a]\n",
        "            return self.MemDFA(w_tail, q_next)\n",
        "\n",
        "    def CompDFA(self):\n",
        "        # Paso 1: Inicializar Q', δ', q0' y F'\n",
        "        Q_prime = self.Q\n",
        "        delta_prime = self.delta\n",
        "        q0_prime = self.q0\n",
        "        F_prime = set()  # Inicialmente vacío\n",
        "\n",
        "        # Paso 2: Completar F'\n",
        "        for q in self.Q:\n",
        "            if q not in self.F:\n",
        "                F_prime.add(q)\n",
        "\n",
        "        # Retornar el nuevo DFA complementado\n",
        "        return DFA(Q_prime, self.Sigma, delta_prime, q0_prime, F_prime)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NFA\n",
        "\n",
        "Considerando una clase simple NFA, la cual es capaz de imprimir los estados y las transacciones de una manera comprensiva."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NFA:\n",
        "    def __init__(self, states, alphabet, transitions, start_state, final_states) -> None:\n",
        "        \"\"\"\n",
        "        Constructor de NFA\n",
        "        Args:\n",
        "            states (list<str>): Lista de todos los estados\n",
        "            alphabet (list<str>): Lista de las letras del alfabeto\n",
        "            transitions (dict): Funcion de transicion\n",
        "            start_state (str): Estado inicial\n",
        "            final_states (list<str>): Lista de los estados finales\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.states = states\n",
        "        self.alphabet = alphabet\n",
        "        self.transitions = transitions\n",
        "        self.start_state = start_state\n",
        "        self.final_states = final_states\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"\n",
        "        Imprime los estados y transiciones de los estados\n",
        "        \"\"\"\n",
        "        transitions_str = '\\n'.join(\n",
        "            [f\"{state} --{symbol}--> {', '.join(next_states)}\"\n",
        "             for state, paths in self.transitions.items()\n",
        "             for symbol, next_states in paths.items()]\n",
        "        )\n",
        "        return (\n",
        "            f\"States: {self.states}\\n\"\n",
        "            f\"Alphabet: {self.alphabet}\\n\"\n",
        "            f\"Transitions:\\n{transitions_str}\\n\"\n",
        "            f\"Start State: {self.start_state}\\n\"\n",
        "            f\"Final States: {self.final_states}\\n\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ClY3W5-uLmS"
      },
      "source": [
        "## Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXNWiQlqr0wK"
      },
      "source": [
        "---\n",
        "\n",
        "#### **Problema 1: Construcción e Implementación de `RegtoNFA` con Expresiones Regulares Avanzadas**\n",
        "- **Descripción:**\n",
        "  - Implementa en Python el algoritmo `RegtoNFA` que convierte una expresión regular avanzada, que incluye operadores como repetición variable $\\{m,n\\}$, en un NFA (Autómata Finito No Determinista). Este NFA debe ser capaz de reconocer si algún prefijo de un texto dado pertenece al lenguaje $L(\\Sigma^*p)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "jX7RgD6Qs9S7"
      },
      "outputs": [],
      "source": [
        "class RegToNFA:\n",
        "    def __init__(self):\n",
        "        self.state_count = 0\n",
        "\n",
        "    def _new_state(self):\n",
        "        self.state_count += 1\n",
        "        return f\"S{self.state_count}\"\n",
        "\n",
        "    def regex_to_nfa(self, regex):\n",
        "        return self._regex_to_nfa_helper(regex)\n",
        "\n",
        "    def _regex_to_nfa_helper(self, regex):\n",
        "        if regex == '':\n",
        "            return self._empty_nfa()\n",
        "        elif len(regex) == 1:\n",
        "            return self._single_char_nfa(regex)\n",
        "        elif '|' in regex:\n",
        "            return self._union_nfa(regex)\n",
        "        elif '*' in regex:\n",
        "            return self._kleene_star_nfa(regex)\n",
        "        else:\n",
        "            return self._concat_nfa(regex)\n",
        "\n",
        "    def _empty_nfa(self):\n",
        "        start_state = self._new_state()\n",
        "        final_state = self._new_state()\n",
        "        return NFA(\n",
        "            states={start_state, final_state},\n",
        "            alphabet=set(),\n",
        "            transitions={},\n",
        "            start_state=start_state,\n",
        "            final_states={final_state}\n",
        "        )\n",
        "\n",
        "    def _single_char_nfa(self, char):\n",
        "        start_state = self._new_state()\n",
        "        final_state = self._new_state()\n",
        "        transitions = {start_state: {char: {final_state}}}\n",
        "        return NFA(\n",
        "            states={start_state, final_state},\n",
        "            alphabet={char},\n",
        "            transitions=transitions,\n",
        "            start_state=start_state,\n",
        "            final_states={final_state}\n",
        "        )\n",
        "\n",
        "    def _concat_nfa(self, regex):\n",
        "        first_nfa = self._regex_to_nfa_helper(regex[0])\n",
        "        rest_nfa = self._regex_to_nfa_helper(regex[1:])\n",
        "\n",
        "        first_nfa.transitions[first_nfa.final_states.pop()] = {\n",
        "            '': {rest_nfa.start_state}\n",
        "        }\n",
        "        first_nfa.states.update(rest_nfa.states)\n",
        "        first_nfa.transitions.update(rest_nfa.transitions)\n",
        "        first_nfa.final_states = rest_nfa.final_states\n",
        "\n",
        "        return first_nfa\n",
        "\n",
        "    def _union_nfa(self, regex):\n",
        "        parts = regex.split('|')\n",
        "        nfa1 = self._regex_to_nfa_helper(parts[0])\n",
        "        nfa2 = self._regex_to_nfa_helper(parts[1])\n",
        "\n",
        "        start_state = self._new_state()\n",
        "        final_state = self._new_state()\n",
        "\n",
        "        transitions = {\n",
        "            start_state: {'': {nfa1.start_state, nfa2.start_state}},\n",
        "            **nfa1.transitions,\n",
        "            **nfa2.transitions,\n",
        "            nfa1.final_states.pop(): {'': {final_state}},\n",
        "            nfa2.final_states.pop(): {'': {final_state}},\n",
        "        }\n",
        "\n",
        "        states = {start_state, final_state, *nfa1.states, *nfa2.states}\n",
        "        alphabet = nfa1.alphabet.union(nfa2.alphabet)\n",
        "\n",
        "        return NFA(\n",
        "            states=states,\n",
        "            alphabet=alphabet,\n",
        "            transitions=transitions,\n",
        "            start_state=start_state,\n",
        "            final_states={final_state}\n",
        "        )\n",
        "\n",
        "    def _kleene_star_nfa(self, regex):\n",
        "        inner_regex = regex.replace('*', '')\n",
        "        inner_nfa = self._regex_to_nfa_helper(inner_regex)\n",
        "\n",
        "        start_state = self._new_state()\n",
        "        final_state = self._new_state()\n",
        "\n",
        "        transitions = {\n",
        "            start_state: {'': {inner_nfa.start_state, final_state}},\n",
        "            inner_nfa.final_states.pop(): {'': {inner_nfa.start_state, final_state}},\n",
        "            **inner_nfa.transitions\n",
        "        }\n",
        "\n",
        "        states = {start_state, final_state, *inner_nfa.states}\n",
        "        alphabet = inner_nfa.alphabet\n",
        "\n",
        "        return NFA(\n",
        "            states=states,\n",
        "            alphabet=alphabet,\n",
        "            transitions=transitions,\n",
        "            start_state=start_state,\n",
        "            final_states={final_state}\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nclass TestStringMethods(unittest.TestCase):\\n    def test_upper(self):\\n        self.assertEqual('foo'.upper(), 'FOO')\\n\\nif __name__ == '__main__':\\n    unittest.main()\\n\""
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "class TestStringMethods(unittest.TestCase):\n",
        "    def test_upper(self):\n",
        "        self.assertEqual('foo'.upper(), 'FOO')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "States: {'S1', 'S2'}\n",
            "Alphabet: {'a'}\n",
            "Transitions:\n",
            "S1 --a--> S2\n",
            "Start State: S1\n",
            "Final States: {'S2'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Hay que tomar los ejemplos de aca para hacer el unit test: https://www.tutorialspoint.com/what-is-the-conversion-of-a-regular-expression-to-finite-automata-nfa\n",
        "\n",
        "converter = RegToNFA()\n",
        "nfa = converter.regex_to_nfa('a')\n",
        "print(nfa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LPlBUTus7fR"
      },
      "source": [
        "- **Parte 2:** **Desafío Adicional:** Extiende el NFA para manejar operaciones de intersección y unión en la expresión regular. Justifica cada paso de la construcción y proporciona ejemplos complejos que no solo contengan concatenación y cierre de Kleene, sino también intersección y unión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XopAIEJryfb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVfB2uj8tBQq"
      },
      "source": [
        "\n",
        "#### **Problema 2: Optimización de NFA mediante Eliminación de Transiciones $\\varepsilon$ y Minimización**\n",
        "- **Descripción:**\n",
        "  - Utiliza el NFA construido en el Problema 1, elimina las transiciones $\\varepsilon$ y luego aplica técnicas de minimización para reducir el número de estados manteniendo la equivalencia del autómata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaFBZgh1tXKH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ADBCWp2tUOA"
      },
      "source": [
        "- **Parte 2:** **Desafío Adicional:** Implementa un algoritmo de minimización de NFA basado en particiones de estados equivalentes. Realiza un análisis de eficiencia comparando el NFA original, el NFA sin transiciones $\\varepsilon$, y el NFA minimizado, en términos de cantidad de estados y transiciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-EFarDRtEoz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8Cgpxo3tFPj"
      },
      "source": [
        "#### **Problema 3: Simulación de `PatternMatchingNFA` con Optimización de Búsqueda**\n",
        "- **Descripción:**\n",
        "  - Implementa un simulador en Python que utilice el NFA minimizado del Problema 2 para realizar una coincidencia de patrones eficiente en un texto dado. El simulador debe optimizar la búsqueda mediante heurísticas que reduzcan el número de transiciones exploradas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzzjVJfutaD-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL91D-ibtaZ4"
      },
      "source": [
        "- **Parte 2:** **Desafío Adicional:** Implementa una estrategia de búsqueda paralela para acelerar el proceso de coincidencia en textos grandes, utilizando múltiples hilos o procesos. Analiza el rendimiento de tu implementación en términos de tiempo de ejecución y uso de recursos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wc1i_dMtJKm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYgLUuIjtJjD"
      },
      "source": [
        "\n",
        "#### **Problema 4: Conversión de NFA a DFA y Manejo de la Explosión Exponencial de Estados**\n",
        "- **Descripción:**\n",
        "  - Convierte el NFA minimizado del Problema 2 en un DFA usando `NFAtoDFA`. Dado que la conversión de NFA a DFA puede resultar en una explosión exponencial de estados, implementa técnicas para manejar y mitigar este problema.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mt5A0H1VtdSm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GG3i05XtdpF"
      },
      "source": [
        "- **Parte 2:** **Desafío Adicional:** Diseña e implementa un algoritmo de conversión incremental que solo construya partes del DFA según sea necesario durante la coincidencia de patrones. Esto incluye el concepto de \"DFA bajo demanda\". Evalúa cómo esta técnica afecta el rendimiento en comparación con un DFA preconstruido completo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrkBoKAftMWQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYxKB-5BtNBA"
      },
      "source": [
        "#### **Problema 5: Simulación de `PatternMatchingDFA` con Memorización y Predicción**\n",
        "- **Descripción:**\n",
        "  - Implementa un simulador para el DFA obtenido en el Problema 4. Para mejorar la eficiencia, incorpora técnicas de memorización (almacenamiento en caché de resultados de subproblemas) y predicción de transiciones, anticipando las siguientes letras en el texto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvebcQuCtifX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH3bcfNRti8a"
      },
      "source": [
        "- **Parte 2:** **Desafío Adicional:** Extiende el simulador para manejar textos de gran tamaño, donde se requieren estrategias de almacenamiento y recuperación de datos eficientes. Esto podría incluir la implementación de estructuras de datos avanzadas como árboles de sufijos o tries para gestionar la búsqueda de patrones en grandes volúmenes de texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXVzcL3BtPeu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrbC5dwy02rl"
      },
      "source": [
        "\n",
        "\n",
        "#### **Problema 6: Comparación Empírica y Teórica de `PatternMatchingNFA` vs. `PatternMatchingDFA` en Escenarios Complejos**\n",
        "- **Descripción:**\n",
        "  - Realiza un estudio comparativo entre los algoritmos `PatternMatchingNFA` y `PatternMatchingDFA` en términos de eficiencia, uso de memoria y aplicabilidad en escenarios reales con textos y patrones de alta complejidad.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4nPZ--etlQX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H75AJtQltlir"
      },
      "source": [
        "- **Parte 2:** **Desafío Adicional:** Implementa un modelo híbrido que combine las ventajas del NFA y DFA, utilizando el NFA en etapas tempranas para filtrar posibles coincidencias y el DFA para validar las coincidencias finales. Evalúa este enfoque en comparación con el uso exclusivo de NFA o DFA en términos de precisión y rendimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK92yX4YtRMk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
